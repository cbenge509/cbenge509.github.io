<!DOCTYPE html>
<html lang="en-US">
  <head>
    <!-- Start of Google Analytics code ID -->
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-162315295-1"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-162315295-1');
    </script>
    <!-- End of Google Analytics code ID -->

    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

<!-- Begin Jekyll SEO tag v2.6.1 -->
<title>CRIS BENGE | Enthusiast of all-things data and machine learning.</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="CRIS BENGE" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Data scientist? Maybe. Solution Architect? Perhaps. Enthusiast of all-things data and machine learning? Definitely." />
<meta property="og:description" content="Data scientist? Maybe. Solution Architect? Perhaps. Enthusiast of all-things data and machine learning? Definitely." />
<link rel="canonical" href="https://cbenge509.github.io/" />
<meta property="og:url" content="https://cbenge509.github.io/" />
<meta property="og:site_name" content="CRISTOPHER BENGE" />
<script type="application/ld+json">
{"@type":"WebSite","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"https://cbenge509.github.io/images/cbenge.png"}},"url":"https://cbenge509.github.io/","name":"CRISTOPHER BENGE","headline":"CRISTOPHER BENGE","description":"Data scientist? Possibly. Solution Architect? Perhaps. Enthusiast of all-things data and machine learning? Definitely.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

<link rel="stylesheet" href="/assets/css/style.css?v=5c6c0d052e536554e6d1c455bf0d7882e50eaf76">
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1><a href="https://cbenge509.github.io/">CRIS BENGE</a></h1>
        <img src="/../images/cbenge.png" alt="Logo" width="250" />
        <p>
            <br><br> <font color="#003262"><B>Enthusiast of all-things data and machine learning.</B></font>
            <br><br>I am an Area Solution Architect for the office of the U.S. Healthcare CTO at Microsoft in our U.S. Enterprise Services division.  
            Our mission is to empower all Healthcare organizations in the federal government and commercial sectors to achieve more. <a href="https://www.microsoft.com/en-us/industry/health">#MicrosoftHealth</a>
            <br><br>  <a href="https://www.linkedin.com/in/crisbenge/"><img src="/../images/linkedin_small.png?raw=true" width="25"/> LinkedIn</a> | 
              <a href="https://github.com/cbenge509"><img src="/../images/github_small.png?raw=true" width="25"/> GitHub</a> | 
              <a href="https://cbenge509.github.io/files/Cristopher Benge - Resume (2020).pdf"><img src="/../images/resume_small.png?raw=true" width="25"/> My CV</a> 
        </p>
        <hr>
        <table align="center">
            <tr>
                <td align="center"><a href="https://www.microsoft.com/en-us/industry/health"><img src="/../images/msft_logo.png?raw=true" width="130"></a></td>
                <td align="center"><a href="https://datascience.berkeley.edu/"><img src="/../images/ucb_logo.png?raw=true" width="130"></a></td>
        </table>
      </header>
<section>

            <p><a href="https://cbenge509.github.io/"><img src="/../images/arrow_back.png?raw=true" width="30" /></a></p>

            <!-- START HERE-->
            <p><a href="https://github.com/cbenge509/BERTVision"><img src="/../images/bertvision.png?raw=true" align="center"/></a></p>
            <h2 id="graduate-income-prediction"><a href="https://github.com/cbenge509/BERTVision">BERTVision : <i>A Novel NLP Modeling Technique</i></a></h2>
            <p><strong>UC Berkeley | Natural Language Processing</strong><br><i> Improving span annotation and classification task performance using parameter-efficient model architectures trained on BERTâ€™s hidden state activations.<br><br>w/ William Casey King, PhD (Yale University) <b>|</b> Siduo Jiang (U.C. Berkeley)</i></p>
            <h3><a href="https://github.com/cbenge509/BERTVision/blob/master/paper/external%20version/BERTVision.pdf"> >>> Read our paper here <<< </a></h3>
            <hr />

            <h4 id="project-description">Project Description</h4>
            <p>We present a highly parameter-efficient approach for Question Answering (QA) that significantly reduces the need for extended BERT fine-tuning. Our best model achieves maximal BERT performance at a fraction of the training time and GPU/TPU expense.</p>

            <h4 id="motivation">Model Architecture</h4>
            Our model extracts layer embeddings from BERT, normally discarded during inferencing, and learns from a lightly fine-tuned BERT at a fraction of the GPU/TPU expense while maintaining or exceeding BERTs performance.<br><br>
            <img src="/../images/BERTVision_QA_Model.png" width=350><br><br>

            <h4 id="motivation">Data Pipeline : Span Annotation</h4>
            After fine-tuning BERT at a minimal level, we capture the inferenced embeddings for each example and store them as 3 dimensional arrays (386, 1024, 25).  These arrays are then contracted across the channel dimension using a simple linear transform using learned weights  From there typical modeling approachs, such as convolution, are applied and a prediction for the start and end span are produced.<br><br>
            <img src="/../images/Data_Pipeline_Span_Annotation.png"><br><br>

            <h4 id="motivation">Data Pipeline : Classification</h4>
            The dataset we used for the project is the SQuAD 2.0 Q&amp;A data, which consists of both questions and span answers as well as questions that cannot be answered.  For this latter problem, we focus our models on the task of identifying whether or not a question is answerable in the form of a binary classification task.<br><br>
            <img src="/../images/Data_Pipeline_Binary_Classification.png"><br><br>

            <h4 id="motivation">Results</h4>
            Our best models use less than 1% of the significantly-sized BERT-Large (~335M parameters), while achieving at-or-better results than BERT on both Q&amp;A span annotation and classification tasks.  We were able to achieve these results with both minimal fine-tuning (1 epoch or less) and less training data.<br><br>
            <table>
                <tr>
                    <td><<img src="/../images/QnA_BERT_Training_Performance_plot.png"></td><td><<img src="/../images/BinaryClassification_BERT_Training_Performance_plot.png"></td>
                </tr>
            </table>

            <h4 id="skills">Skills</h4>
            <p>Natural Language Processing, Q&amp;A Span Annotation, Classification, BERT, Transformers, Convolutional Neural Networks, Ensembling</p>

            <h4 id="tools">Tools</h4>
            <p>Python, Jupyter, Pandas, NumPy, Keras, TensorFlow, LaTeX</p>
            <hr />

            <p><a href="https://github.com/cbenge509/BERTVision"><img src="/../images/BERTVision_Development_PIpeline.png" /></a></p>
            <hr />
            <p style="font-size:11px">See the complete project in my <a href="https://github.com/cbenge509/BERTVision">GitHub repository.</a></p>

        </section>

    </div>
    <script src="https://cbenge509.github.io/assets/js/scale.fix.js"></script>
  </body>
</html>